{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd26df5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "SPARK_VERSION = '3.1.2'\n",
    "SCALA_VERSION = '2.12'\n",
    "\n",
    "### adiciona package adicional\n",
    "import findspark\n",
    "findspark.add_packages(['org.apache.spark:spark-sql-kafka-0-10_' + SCALA_VERSION + ':' + SPARK_VERSION ])\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "import mysql.connector as mysql \n",
    "con = mysql.connect(host='localhost',database='teste',user='saulo',password='Olivetti@5!', auth_plugin='mysql_native_password')\n",
    "cursor = con.cursor()\n",
    "\n",
    "### extrai coluna valor do dictionary e grava arquivo .csv  \n",
    "def ProcessaLinha(df_grava):\n",
    "    df_montado = pd.DataFrame([df_grava])\n",
    "    ##for linha in df_grava:\n",
    "    valor = str(df_grava['value'])\n",
    "    timestamp = str(df_grava['timestamp'])\n",
    "    ###df_montado.columns = ['coluna1','coluna2','coluna3','coluna4','coluna5','coluna6','coluna7'] \n",
    "    ##df_montado.to_csv('/tmp/people.csv', mode='a', index=False, sep='|', header=False)\n",
    "    comando = f'''insert into kafka values (\"{valor}\", \"{timestamp}\")'''\n",
    "    print(comando)\n",
    "    #cursor.execute(comando)     \n",
    "    #con.commit()\n",
    "    ##return df_montado\n",
    "        \n",
    "####        for message in consumer:\n",
    "####    message = message.value\n",
    "####    collection.insert_one(message)\n",
    "####    print('{} added to {}'.format(message, collection))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5b57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/06 12:52:29 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-daee7130-d775-44c3-bdc9-a9b14b868e41. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "22/06/06 12:52:29 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "insert into kafka values (\"bytearray(b'msg 340')\", \"2022-06-06 12:48:03.790000\");\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### inicializa instancia spark \n",
    "spark = pyspark.sql.SparkSession \\\n",
    "          .builder \\\n",
    "          .appName(\"APP\") \\\n",
    "          .getOrCreate()\n",
    "\n",
    "### inicia leitura streaming do inicio \n",
    "df = spark\\\n",
    "      .readStream \\\n",
    "      .format(\"kafka\") \\\n",
    "      .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "      .option(\"subscribe\", \"saulo-teste\") \\\n",
    "      .option(\"startingOffsets\",\"\"\" {\"saulo-teste\":{\"0\":0}}\"\"\") \\\n",
    "      .option(\"failOnDataLoss\", \"false\") \\\n",
    "      .load()\n",
    "\n",
    "\n",
    "###query = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"topic\",\"CAST(timestamp AS STRING)\", \"CAST(offset AS STRING)\", \"CAST(partition AS STRING)\" ) \\\n",
    "query = df.writeStream \\\n",
    "    .foreach(ProcessaLinha) \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
